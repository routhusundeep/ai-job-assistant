% !TeX program = tectonic
% !TeX root = report.tex
\documentclass[sigconf]{acmart}

\AtBeginDocument{%
  \providecommand\BibTeX{{Bib\TeX}}
}


\setcopyright{acmlicensed}
\copyrightyear{2024}
\acmYear{2024}
\acmDOI{10.1145/0000000.0000000}

\acmConference[CS599 2024]{CS599 AI Job Assistant Project}{December 2024}{Boston, MA}
\acmISBN{978-1-4503-0000-0/24/12}

\begin{document}

\title{AI-Powered Job Application Assistant}

\author{Sundeep Routhu}
\affiliation{%
  \institution{Boston University}
  \city{Boston}
  \state{MA}
  \country{USA}
}
\email{srouthu@bu.edu}

\renewcommand{\shortauthors}{Routhu}


\begin{abstract}
  Modern job seekers juggle dozens of rapidly changing LinkedIn postings, repeatedly tailor resumes, and draft outreach messages with little feedback on which applications deserve attention. This project delivers an end-to-end, auditable AI workflow that automates those steps while keeping all artifacts local. A Playwright-based scraper logs into LinkedIn with stored credentials, applies configurable filters, and persists recruiter- and salary-enriched postings into SQLite. A ranking CLI embeds each description, compares it against the master resume with FAISS search plus optional LLM reranking, and surfaces the highest-fit roles. Gemini-powered agents then tailor resumes, score fit, and generate email plus LinkedIn outreach drafts, all recorded for auditing. A FastAPI + Alpine.js dashboard exposes the pipeline outputs, and a Chrome autofill extension injects the tailored assets into job forms. Together, these stages cut manual effort, shorten time per application, and establish a reusable foundation for future recruiter discovery and analytics.
\end{abstract}

\keywords{job automation, LinkedIn scraping, resume ranking, LLM agents, application workflows}

\maketitle


\section{Introduction}
Job seekers repeatedly cycle through high-effort application loops where they must scan new postings, interpret recruiter expectations, and sustain motivation while unemployed or underemployed. Empirical meta-analyses confirm that the cognitive and emotional load of modern job search correlates strongly with employment outcomes, making the process “work about work’’ rather than value creation \cite{vanhooft2021jobsearch,kanfer2001job,wanberg2012individual}. Daily studies further show that self-efficacy and planning discipline determine whether applicants keep momentum amid rapid shifts in available roles \cite{liu2014daily}. Interviews and practitioner guidance echo that searching “hard’’ is insufficient without systematic tracking and timely action as listings churn on social platforms \cite{gursakal2020jobseeking,vanhoye2022systematic}.

Simultaneously, job descriptions and applicant tracking systems (ATS) demand tailored materials that reflect employer language, yet such customization is tedious and risky to perform manually at scale. Research on applicant behavior highlights that resume edits and outreach quality influence recruiter responses, but most candidates lack tooling to evaluate fit or version their materials with auditability \cite{horton2023algorithmic,newman2020applicant}. As companies increasingly automate screening, the absence of transparent, local-first workflows raises fairness and accountability concerns for both seekers and institutions \cite{bogen2018helpwanted}.

This report introduces an AI-powered job assistant that unifies LinkedIn scraping, vector-based ranking, LLM-tailored resumes, outreach drafting, and a Chrome autofill extension into a single auditable pipeline. Built atop Playwright automation \cite{microsoft2023playwright}, SQLite persistence \cite{hipp2023sqlite}, FastAPI services \cite{fastapi2022docs}, and Gemini-class language models \cite{deepmind2024gemini}, the system keeps every artifact local for inspection in line with emerging auditing guidance \cite{raji2020closing,selbst2019fairness}. We describe the multi-stage architecture, situate it within prior work on job search and AI assistance, and evaluate how it reduces time per application while preserving traceability.

\section{Related Work}

\subsection{Job Search Behavior and Hiring Pipelines}
Quantitative reviews of the job-search experience demonstrate that persistence, structured planning, and psychological resources explain a large portion of employment variance \cite{vanhooft2021jobsearch,kanfer2001job,wanberg2012individual}. Daily-diary studies show that job-search self-efficacy mediates how candidates respond to setbacks \cite{liu2014daily}, while practitioner narratives reinforce the need for systematic tracking as platform feeds shift \cite{vanhoye2022systematic,gursakal2020jobseeking}. On the employer side, recruiting scholarship documents how ATS tooling mediates resume intake and often obscures decision criteria, motivating transparent, auditable workflows for both applicants and organizations \cite{acikgoz2019employee,newman2020applicant,bogen2018helpwanted}.

\subsection{Resume--Job Matching and Similarity Search}
Person--job fit modeling has progressed from handcrafted scoring to deep architectures that learn joint representations of resumes and descriptions \cite{qin2018matching,wu2020learning,lu2020multiview,zhang2022twoway}. Commercial systems increasingly rely on vector search to scale matching, with research prototypes such as Resume2Vec highlighting improvements for ATS pipelines \cite{shao2023vectorsearch,pal2025resume2vec}. Our ranking stage builds on this line by embedding descriptions and resumes via transformer models \cite{reimers2019sentencebert,gao2021berttraining} and executing approximate nearest-neighbor retrieval using FAISS \cite{johnson2017billion,guo2020faissgpu}, while optionally sending top candidates to LLM-based rerankers that capture nuanced context fit \cite{horton2023algorithmic}.

\subsection{LLMs, Reranking, and Agent Automation}
Large language models have achieved strong few-shot performance for reasoning and generation tasks, enabling downstream systems to refine search results and craft domain-specific narratives \cite{brown2020language,openai2024gpt4o,deepmind2024gemini}. Dense and late-interaction rerankers such as BERT-based pipelines, ColBERT, and RAG hybrids demonstrate how LLMs can complement vector retrieval \cite{nogueira2019passage,khattab2020colbert,lewis2020rag}. Recent multi-agent frameworks highlight the feasibility of orchestrating specialized LLM roles for planning, critique, and action in complex workflows \cite{liang2023holistic,wang2023voyager,xi2024autogen}. Our assistant applies these insights by delegating resume tailoring, fit analysis, and outreach drafting to Gemini-powered flows while logging each output for review.

\subsection{Scraping, Infrastructure, and Ethical Considerations}
Browser automation frameworks such as Playwright and Chrome Headless provide resilient primitives for interacting with modern, script-heavy sites \cite{microsoft2023playwright,chromedevtools2023headless}. Ethical guidelines emphasize respecting platform terms, documenting collection logic, and safeguarding user data throughout scraping activities \cite{munz2020ethical,hovy2016social}. To maintain a verifiable record of every action, we persist artifacts in SQLite \cite{hipp2023sqlite,owens2010sqlite}, serve them through FastAPI with Pydantic validation \cite{fastapi2022docs,pydantic2023docs}, and expose lightweight dashboards via Alpine.js plus Chrome extensions compliant with Manifest V3 \cite{alpine2023docs,chrome2023extensions}. These choices align with broader calls for fairness, transparency, and auditability in sociotechnical systems \cite{selbst2019fairness,mitchell2019modelcards,raji2020closing}.

\section{System Overview}
Describe the overall architecture: CLI scraper, SQLite persistence, embedding-based ranking CLI, FastAPI dashboard, Gemini-powered agents, and the Chrome autofill extension. Include mentions of key configs (e.g., `config/scraping.yaml`) and figure placeholders for the architecture diagram.

\section{Stage 1: Scraping and Persistence}
Explain how Playwright logs into LinkedIn, applies filters, parses job cards, and stores structured results in SQLite. Highlight rate limiting, selectors, salary and recruiter extraction, and logging/audit considerations.

\section{Stage 2: Ranking and Fit Analysis}
Detail the embedding workflow (model choice, FAISS index, cache tables), the CLI interface, and the optional LLM reranking. Discuss scoring outputs and how they update the database and dashboard.

\section{Stage 3: Tailoring and Outreach Agents}
Outline the Gemini flows for resume tailoring, fit analysis, and outreach. Describe prompt design, guardrails, resume version management, and storage of outputs for auditing.

\section{Chrome Autofill Extension}
Document the extension architecture: field detection, backend endpoints (`/extension/autofill` and `/extension/resume`), resume upload flow, and how it interacts with tailored assets.

\section{Evaluation and Results}
Define the metrics you will report (time per application, ranking precision, cost per run, qualitative feedback). Placeholder text goes here until real results are inserted.

\section{Discussion and Limitations}
Capture lessons learned about rate limits, LLM reliability, ethical guardrails, data privacy, and other constraints.

\section{Conclusion and Future Work}
Summarize the impact of the project and outline next steps such as recruiter discovery, analytics, or automated orchestration. Reinforce how the stages fit together.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
